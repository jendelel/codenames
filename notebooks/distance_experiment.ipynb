{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noqa\n",
    "import numpy as np\n",
    "import scipy\n",
    "import gensim\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Google's pre-trained Word2Vec model.\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "nouns = set(x.name().split('.', 1)[0] for x in wn.all_synsets('n'))\n",
    "frequent_words = set(x.name().split('.', 1)[0] for x in wn.all_synsets())\n",
    "\n",
    "\n",
    "def filter_word(key):\n",
    "    return key.isalpha() and key.islower() and key in frequent_words\n",
    "\n",
    "\n",
    "def read_words(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        for word in f:\n",
    "            yield word.strip().lower()\n",
    "\n",
    "\n",
    "card_frequent = set(read_words('./frequent_words.txt'))\n",
    "\n",
    "\n",
    "def filter_cards(key):\n",
    "    return filter_word(key) and key in nouns and key in card_frequent\n",
    "\n",
    "\n",
    "unfiltered_vocab = set(key for key in model.vocab.keys() if filter_word(key))\n",
    "filtered_vocab = set(key for key in unfiltered_vocab if key in card_frequent)\n",
    "vocab = unfiltered_vocab\n",
    "card_vocab = set(key for key in filtered_vocab if filter_cards(key))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unfiltered_vocab), len(vocab), len(card_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import environment as env\n",
    "from environment import Team\n",
    "master = env.DistanceMaster(model, vocab, card_vocab)\n",
    "guesser = env.DistanceGuesser(model, vocab, card_vocab)\n",
    "generator = env.StateGenerator(model, vocab, card_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate clue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clue\n",
    "from copy import deepcopy\n",
    "\n",
    "print('')\n",
    "state = generator.generate_state()\n",
    "tru_state = deepcopy(state)\n",
    "\n",
    "print('Hidden:', state.hidden_str)\n",
    "print('Giving clue...')\n",
    "clue = master.give_clue(state, team=Team.BLUE)\n",
    "print('Clue:', clue.word, clue.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate guesses\n",
    "for i in range(clue.number):\n",
    "    iteration = i + 1\n",
    "    guess = guesser.guess(state, clue, iteration, team=Team.BLUE)\n",
    "    print(' Guess ', iteration, ':', guess)\n",
    "    if guess in state.blue:\n",
    "        state.blue.remove(guess)\n",
    "    else:\n",
    "        break\n",
    "print('Whole clue: ', clue)\n",
    "print('Truth:', tru_state.truth_str)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
